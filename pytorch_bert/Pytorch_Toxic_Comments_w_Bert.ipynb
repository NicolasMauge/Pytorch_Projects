{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NicolasMauge/learning_projects/blob/master/Pytorch_Toxic_Comments_w_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjilT4VZSE3X"
   },
   "source": [
    "# Set up of the Google Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ZNofz0k5XOgA",
    "outputId": "3d5fb7c7-445a-43ee-ef40-3dfa5b28b345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "fqDLwzQg5xkm",
    "outputId": "da61c572-e0bd-4356-f464-cb92336cd962"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/apex.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4848
    },
    "colab_type": "code",
    "id": "MuBDKLyYRF0E",
    "outputId": "a4915c6f-889d-460e-9455-e974a0db080a"
   },
   "outputs": [],
   "source": [
    "!cd apex ; pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "OL93qTK_IAgv",
    "outputId": "ee50d82d-c43a-4e6c-84e4-b1d0828fa3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apex  data  logs  model  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1339
    },
    "colab_type": "code",
    "id": "wMch6Hkr8Uhj",
    "outputId": "0a6a6bfd-c379-4685-bc3d-cf2cf1fea55b"
   },
   "outputs": [],
   "source": [
    "!pip install fast-bert\n",
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwD49vEFSRXW"
   },
   "source": [
    "# Download of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEX9anXkT7gU"
   },
   "source": [
    "Before running the next cell, please change the username (xxx) and key (yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "36UIRSz9E2q2",
    "outputId": "97bdb602-4c27-4e49-e75e-3de6fc91c6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kaggle.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile kaggle.json\n",
    "{\"username\":\"xxx\",\"key\":\"yyy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czXCPbIcgZ2s"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle/ ; mv kaggle.json ~/.kaggle/ ; chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsALgjKIFEvo"
   },
   "outputs": [],
   "source": [
    "!mkdir data ; cd data ; mkdir toxic_comments\n",
    "!cd data ; cd toxic_comments ; kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
    "!ls ; cd data/toxic_comments ; ls\n",
    "!cd data ; cd toxic_comments ; unzip train.csv.zip ; unzip test.csv.zip ; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kld5Q0Z_PP9q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dat = pd.read_csv(\"data/toxic_comments/train.csv\")\n",
    "print(dat.columns)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpWHDydmhyaG"
   },
   "outputs": [],
   "source": [
    "labels_list = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "labels_pandas = pd.DataFrame(labels_list)\n",
    "labels_pandas.to_csv(\"data/toxic_comments/labels.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLGGaYLsigva"
   },
   "outputs": [],
   "source": [
    "!cat data/toxic_comments/labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "Q0oywfnweAhr",
    "outputId": "f7e91113-df8e-489c-ee42-b228fafe7148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train.csv\tsample_submission.csv.zip  test_labels.csv.zip\n",
      "data_valid.csv\ttest.csv\t\t   train.csv\n",
      "labels.csv\ttest.csv.zip\t\t   train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "!cd data ; cd toxic_comments ; ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7kgFxE9gFm1"
   },
   "source": [
    "Split train / valid (80% / 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "TkQ74QzxgEk_",
    "outputId": "741a9538-7b3f-4d60-a9d2-58c784c9346e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571 127656 31915\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/toxic_comments/train.csv\")\n",
    "train, valid = np.split(df.sample(frac=1), [int(.8*len(df))])\n",
    "print(len(df), len(train), len(valid))\n",
    "\n",
    "train.to_csv(\"data/toxic_comments/data_train.csv\", index=False)\n",
    "valid.to_csv(\"data/toxic_comments/data_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-UdPJmWSajy"
   },
   "source": [
    "# Convert google model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJXcKQq5T0lA"
   },
   "source": [
    "## Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "-0y9JH_QSeRk",
    "outputId": "970b8375-46b3-4ab4-e18a-92f3de5755af"
   },
   "outputs": [],
   "source": [
    "!mkdir model ; cd model ; wget \"https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\"\n",
    "!cd model ; unzip multi_cased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "cpCT8CPTUCMP",
    "outputId": "06bb8081-2e1b-42bc-ebcb-a169fd22086b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_config.json\t\t     bert_model.ckpt.index  pytorch_model.bin\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta   vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!cd model ; cd multi_cased_L-12_H-768_A-12 ; ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9jZIyDWUQtR"
   },
   "source": [
    "## Convert the model in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO-jShCaYNgq"
   },
   "source": [
    "Converted model: model/multi_cased_L-12_H-768_A-12/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8224
    },
    "colab_type": "code",
    "id": "kIfoHF6BUUR1",
    "outputId": "73ce83b5-0520-4397-b27b-af35cb1ddcc2"
   },
   "outputs": [],
   "source": [
    "!export BERT_BASE_DIR=model/multi_cased_L-12_H-768_A-12 ; pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch $BERT_BASE_DIR/bert_model.ckpt $BERT_BASE_DIR/bert_config.json $BERT_BASE_DIR/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Esvj65zznkGN"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnoagZrsnkmx"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tswFD-Vk2zx2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import apex\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from fast_bert.data import BertDataBunch\n",
    "from fast_bert.learner import BertLearner\n",
    "from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, roc_auc\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ne--O6e9d3Q"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data/toxic_comments/')     # path for data files (train and val)\n",
    "LABEL_PATH = Path('data/toxic_comments/')  # path for labels file\n",
    "MODEL_PATH=Path('models/')    # path for model artifacts to be stored\n",
    "LOG_PATH=Path('logs/')       # path for log files to be stored\n",
    "\n",
    "# location for the pretrained BERT models\n",
    "BERT_PRETRAINED_PATH = Path('model/multi_cased_L-12_H-768_A-12/')\n",
    "\n",
    "args = {\n",
    "    \"run_text\": \"multilabel toxic comments with freezable layers\",\n",
    "    \"max_seq_length\": 256,\n",
    "    \"do_lower_case\": False,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"learning_rate\": 5e-6,\n",
    "    \"num_train_epochs\": 12.0,\n",
    "    \"warmup_proportion\": 0.002,\n",
    "    \"local_rank\": -1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"fp16\": False,\n",
    "    \"loss_scale\": 128\n",
    "}\n",
    "\n",
    "LOG_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VPh0MSdlifd"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "FsBZgLkB9pnN",
    "outputId": "ccabab4b-c780-4aa0-9158-7605e51ccf1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/04/2019 13:43:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file model/multi_cased_L-12_H-768_A-12/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_PATH, \n",
    "                                          do_lower_case=args['do_lower_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKplCNN9dwxn"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# check if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpu = True\n",
    "else:\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrHHkTsod1Cb"
   },
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "databunch = BertDataBunch(DATA_PATH, LABEL_PATH, tokenizer, \n",
    "                          train_file='data_train.csv', val_file='data_valid.csv', \n",
    "                          text_col=\"comment_text\", label_col=label_cols,\n",
    "                          bs=args['train_batch_size'], maxlen=args['max_seq_length'], \n",
    "                          multi_gpu=multi_gpu, multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uotnwhaB9wle"
   },
   "outputs": [],
   "source": [
    "## from fast_bert / learner.py\n",
    "import os\n",
    "from fast_bert.data import BertDataBunch, InputExample, InputFeatures\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, ConstantLR, WarmupCosineSchedule, WarmupConstantSchedule, WarmupLinearSchedule, WarmupCosineWithWarmupRestartsSchedule, WarmupCosineWithHardRestartsSchedule\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertLayerNorm\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "\n",
    "class BertLearner_freeze(BertLearner):\n",
    "    @staticmethod\n",
    "    def from_pretrained_model(dataBunch, pretrained_path, metrics, device, logger, finetuned_wgts_path=None, \n",
    "                              multi_gpu=True, is_fp16=True, loss_scale=0, warmup_proportion=0.1, \n",
    "                              grad_accumulation_steps=1, multi_label=False):\n",
    "        \n",
    "        model_state_dict = None\n",
    "        \n",
    "        if finetuned_wgts_path:\n",
    "            model_state_dict = torch.load(finetuned_wgts_path)\n",
    "        \n",
    "        if multi_label == True:\n",
    "            model = BertForMultiLabelSequenceClassification.from_pretrained(pretrained_path, \n",
    "                                                                  num_labels = len(dataBunch.labels), \n",
    "                                                                  state_dict=model_state_dict)\n",
    "        else:\n",
    "            model = BertForSequenceClassification.from_pretrained(pretrained_path, \n",
    "                                                                  num_labels = len(dataBunch.labels), \n",
    "        # line added to freeze the pretrained layers \n",
    "        # ==>                                                    state_dict=model_state_dict)\n",
    "        model.freeze_bert_encoder()     \n",
    "        # <==\n",
    "                                                             \n",
    "        if is_fp16:\n",
    "            model = model.half()\n",
    "        \n",
    "        model.to(device)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            if multi_gpu == False:\n",
    "                try:\n",
    "                    from apex.parallel import DistributedDataParallel as DDP\n",
    "                except ImportError:\n",
    "                    raise ImportError(\"Please install apex to use distributed and fp16 training.\")\n",
    "\n",
    "                model = DDP(model)\n",
    "            else:\n",
    "                model = torch.nn.DataParallel(model)\n",
    "            \n",
    "        return BertLearner(dataBunch, model, pretrained_path, metrics, device, logger, \n",
    "                multi_gpu, is_fp16, loss_scale, warmup_proportion, grad_accumulation_steps, multi_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "RWWDqQqXkESB",
    "outputId": "58fd2713-0b84-4915-c8f8-f107002a73ee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "metrics.append({'name': 'accuracy_single', 'function': accuracy_multilabel})\n",
    "\n",
    "learner = BertLearner_freeze.from_pretrained_model(databunch, BERT_PRETRAINED_PATH, metrics, device, logger, \n",
    "                                            finetuned_wgts_path=None, \n",
    "                                            is_fp16=args['fp16'], loss_scale=args['loss_scale'], \n",
    "                                            multi_gpu=multi_gpu,  multi_label=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "3PDNjVKcYWtX",
    "outputId": "49c4de51-bd54-46fd-c160-34b63f28227f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_grad = [param.requires_grad for param in learner.model.parameters() if param.requires_grad==True]\n",
    "\n",
    "list_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "7o4aTqrfku1t",
    "outputId": "239309d6-3e75-49a4-ad4b-f477f1314e9e"
   },
   "outputs": [],
   "source": [
    "learner.fit(4, lr=args['learning_rate'], \n",
    "            schedule_type=\"warmup_cosine_hard_restarts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5e_Wv8yOUvHd"
   },
   "source": [
    "(needs a confirmation) fastbert doesn't have yet the capacity to freeze the pretrained layers with an option. I created a workaround with the class BertLearner_freeze(BertLearner).\n",
    "Problem: this class is incompatible with float precision 16 in apex (pb when the tensors are flatten during back-propagation). "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Pytorch_Toxic_Comments_w_Bert",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
